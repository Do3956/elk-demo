# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5000
  }
}
filter {
  # 去掉不必要的默认日志字段
  mutate {
    remove_field => [ "input", "ecs", "@metadata", "@version", "tags"]
  }

  # 将message内容拆分，dissect和grok：资源消耗少，但它只能处理格式相似，且有分隔符的字符串
  dissect {
    mapping => {
      "message" => '%{client_ip} - %{account_id} [%{nginx_time}] "%{request}" %{status} %{body_bytes_sent} "%{http_referer}" "%{user_agent}" "%{http_x_forwarded_for}" "%{request_time}"%{}'
    }
    # convert_datatype => {
    #   body_bytes_sent => "int"
    #   account_id => "int"
    #   status => "int"
    #   request_time => "float"
    # }
  }

  urldecode {
    charset => "UTF-8"
    field => "request"
  }

  # 去掉lb健康监测的日志
  # ex: 119.29.48.232 - - [19/Mar/2020:20:41:13 +0800] "HEAD / HTTP/1.1" 200 0 "-" "-" "-" "0.000"
  if ([body_bytes_sent] == "0") and ([request] =~ /^HEAD.*/) {
    drop { }
  }

  if ([request] =~ /\.(js|css)/) {
    drop { }
  }

  grok {
    match => {
      "request" => [
        "%{WORD:method} %{GREEDYDATA:url}\?%{GREEDYDATA:param_string} HTTP/%{NUMBER:httpversion}",
        "%{WORD:method} %{GREEDYDATA:url} HTTP/%{NUMBER:httpversion}",
        "%{WORD:method} %{NOTSPACE:bad_url} HTTP/%{NUMBER:httpversion}"
      ]
      break_on_match => true
    }
  }

  # 去掉不需要统计的日志：上一步 grok 匹配失败的日志
  if ("_grokparsefailure" in [tags]) {
    drop { }
  }

  # 用户来源处理
  if [user_agent] =~ /^Lycheer/ {
    kv {
      source => "user_agent"
      target => "ua"
      field_split => " "
      value_split => "/"
    }
  } else {
    useragent {
      # TODO: sometimes problem abount parsing ua if source == target
      source => "user_agent"
      target => "ua"
    }
  }

  date {
    locale => "en"
    match => [ "nginx_time", "dd/MMM/yyyy:HH:mm:ss Z" ]
    timezone => "Asia/Shanghai"
  }

  # 参数拆分
  if ([param_string]) and ("=" in [param_string]){
    kv {
      source => "param_string"
      target => "param"
      field_split => "&"
    }
    mutate {
      remove_field => ["param_string"]
    }
  }

  # 定义字段类型
  mutate {
    convert => {
      "body_bytes_sent" => "integer"
      "account_id" => "integer"
      "status" => "integer"
      "request_time" => "float"
    }
    copy => { "url" => "url_pattern" }
    # remove_field => ["message", "request", "httpversion"]
  }

  # 支持数字匹配
  mutate {
    gsub => [
      "url_pattern", "[0-9]+", ":number"
    ]
  }

}
output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "content-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
}
